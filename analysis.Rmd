---
title: "Climate-Socioeconomic Pipeline (R)"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
---

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(readxl)
library(sf)
library(terra)
library(randomForest)
library(jsonlite)
theme_set(theme_minimal())
# Limit terra memory usage and spill to disk
terraOptions(memfrac = 0.5, todisk = TRUE, parallel = FALSE)
```

## Paths
Update these if you relocated the raw downloads.

```{r paths}
# Set this to your Windows project root (adjust if your drive/folder differs)
windows_root <- "D:/IIT Sem3/Data Preparation and Analysis CSP-571/All project/Impact-of-Environmental-Factors-on-Socioeconomic-Outcomes"

lgii_default <- file.path(windows_root, "data", "Nasa Earth Data", "spatialecon-lgii-measures-v1-xlsx.xlsx")
lgii_sample <- file.path(windows_root, "data", "sample", "lgii_sample.csv")  # set use_sample_lgii <- TRUE only if testing
use_sample_lgii <- FALSE

kaggle_dir <- file.path(windows_root, "data", "Kaggle Dataset")   # adjust if your folder is named differently (e.g., 'data/Kaggle Data')

if (file.exists(lgii_default)) {
  lgii_path <- lgii_default
} else if (use_sample_lgii && file.exists(lgii_sample)) {
  lgii_path <- lgii_sample
} else {
  stop("LGII Excel not found at ", lgii_default, ". Set the correct path or enable use_sample_lgii for the toy CSV.")
}

lgii_path <- normalizePath(lgii_path, winslash = "/", mustWork = TRUE)
kaggle_dir <- normalizePath(kaggle_dir, winslash = "/", mustWork = TRUE)
cat("Using LGII at:", lgii_path, "\n")
cat("Using Kaggle data at:", kaggle_dir, "\n")
```

## Helpers

```{r helpers}
standardize_iso <- function(x) toupper(trimws(as.character(x)))
coerce_year <- function(x) suppressWarnings(as.integer(as.character(x)))

zscore <- function(x) {
  s <- sd(x, na.rm = TRUE)
  m <- mean(x, na.rm = TRUE)
  if (is.na(s) || s == 0) return(rep(0, length(x)))
  (x - m) / s
}

minmax <- function(x) {
  rng <- range(x, na.rm = TRUE)
  if (diff(rng) == 0) return(rep(0, length(x)))
  (x - rng[1]) / (diff(rng) + 1e-9)
}

to_unc <- function(p) {
  if (is.na(p)) return(NA_character_)
  paste0("\\\\?\\", normalizePath(p, winslash = "\\", mustWork = FALSE))
}

find_file <- function(base_dir, pattern) {
  hits <- list.files(base_dir, pattern = pattern, recursive = TRUE, full.names = TRUE)
  if (length(hits) > 0) normalizePath(hits[[1]], winslash = "/", mustWork = FALSE) else NA_character_
}
```

## Load LGII

```{r load-lgii}
if (!file.exists(lgii_path)) {
  stop("LGII file not found. Checked: ", lgii_path, " and ", lgii_default, ". Place the NASA Excel there or set lgii_path manually.")
}

lgii <- if (grepl("\\.xlsx$", lgii_path, ignore.case = TRUE)) {
  lg_raw <- read_excel(lgii_path, sheet = "Data") %>%
    janitor::clean_names()
  country_col <- intersect(c("iso", "country_iso", "country"), names(lg_raw))
  country_col <- if (length(country_col) > 0) country_col[[1]] else NA_character_
  gini_col <- intersect(c("gini_weighted", "gini"), names(lg_raw))
  gini_col <- if (length(gini_col) > 0) gini_col[[1]] else NA_character_
  if (is.na(country_col)) stop("Could not find a country/iso column in LGII.")
  lg_raw %>%
    mutate(
      country_iso = standardize_iso(.data[[country_col]]),
      gini = if (!is.na(gini_col)) .data[[gini_col]] else NA_real_
    )
} else {
  read_csv(lgii_path, show_col_types = FALSE) %>%
    janitor::clean_names() %>%
    mutate(
      country_iso = standardize_iso(coalesce(country_iso, iso, country)),
      gini = if ("gini" %in% names(.)) gini else NA_real_
    )
}

lgii <- lgii %>%
  mutate(
    year = coerce_year(year)
  ) %>%
  drop_na(country_iso, year)

glimpse(lgii)
```

## Country Shapes (Natural Earth)

```{r shapes}
world <- rnaturalearth::ne_countries(scale = "medium", returnclass = "sf") %>%
  mutate(country_iso = toupper(iso_a3)) %>%
  filter(country_iso != "-99") %>%
  select(country_iso, geometry)

plot(st_geometry(world))
```

## Raster Extraction Utilities

```{r raster-helpers}
extract_stat <- function(shapes, raster_path, fun = "mean", band = 1,
                         fact = 40,      # more aggressive downsampling
                         use_zonal = TRUE) {
  if (!file.exists(raster_path)) {
    warning("Missing raster: ", raster_path)
    return(tibble(country_iso = shapes$country_iso, value = NA_real_))
  }

  # Load single band only to avoid loading full stack
  r <- rast(raster_path)
  if (band > nlyr(r)) stop("Band ", band, " not in raster.")
  r <- r[[band]]

  # Align CRS
  if (!is.na(crs(r)) && crs(r) != crs(shapes)) {
    shapes <- st_transform(shapes, crs(r))
  }

  # Crop early
  r <- crop(r, vect(shapes))

  # Heavy downsample to save RAM
  r <- aggregate(
    r, fact = fact, fun = mean, na.rm = TRUE,
    filename = tempfile(fileext = ".tif"), overwrite = TRUE
  )

  shapes$id <- seq_len(nrow(shapes))

  if (use_zonal) {
    z <- tryCatch(
      terra::zonal(r, vect(shapes), fun = fun, na.rm = TRUE),
      error = function(e) NULL
    )
    if (!is.null(z)) {
      vals <- rep(NA_real_, nrow(shapes))
      vals[match(z$zone, shapes$id)] <- z[[ncol(z)]]
      return(tibble(country_iso = shapes$country_iso, value = vals))
    }
  }

  ex <- terra::extract(r, vect(shapes), fun = match.fun(fun), na.rm = TRUE)
  vals <- ex[, 2]
  tibble(country_iso = shapes$country_iso, value = vals)
}
```

```{r}
temp_path <- "data/Kaggle Dataset/11_temperature/World_TEMP_GISdata_LTAy_GlobalSolarAtlas-v2_GEOTIFF/World_TEMP_GISdata_LTAy_GlobalSolarAtlas_GEOTIFF/TEMP.tif"
print(temp_path)
file.exists(temp_path)
```

## Environmental Features (Kaggle rasters)

```{r env-extract}
list_and_normalize <- function(dir, pattern, label) {
  hits <- list.files(dir, pattern = pattern, recursive = TRUE, full.names = TRUE)
  cat(label, "candidates found:", length(hits), "\n")
  if (length(hits) == 0) return(NA_character_)
  first <- hits[1]
  cat(paste0("  [1] ", first, "\n"))
  to_unc(first)
}

temp_path <- list_and_normalize(kaggle_dir, "TEMP.tif$", "TEMP")
pop_path  <- list_and_normalize(kaggle_dir, "GHS_POP_E2015_GLOBE_R2019A_54009_250_V1_0\\.tif$", "POP")
veg_path  <- list_and_normalize(kaggle_dir, "ESACCI-LC-L4-LCCS-Map-300m-P1Y-2015-v2\\.0\\.7\\.tif$", "VEG")
haz_path  <- list_and_normalize(kaggle_dir, "Goode_FinalClassification_19_05pcnt_prj\\.tif$", "HAZ")
gdp_path  <- list_and_normalize(kaggle_dir, "GDP_PPP_1990_2015_5arcmin_v2\\.nc$", "GDP")

# Explicit override for temperature path if auto-discovery fails (UNC Windows path)
if (is.na(temp_path) || !file.exists(temp_path)) {
  temp_path <- to_unc(
    file.path(
      windows_root, "data", "Kaggle Dataset", "11_temperature",
      "World_TEMP_GISdata_LTAy_GlobalSolarAtlas-v2_GEOTIFF",
      "World_TEMP_GISdata_LTAy_GlobalSolarAtlas_GEOTIFF",
      "TEMP.tif"
    )
  )
}

cat("Resolved temp_path:", temp_path, "exists:", file.exists(temp_path), "\n")
cat("Resolved pop_path :", pop_path,  "exists:", file.exists(pop_path),  "\n")
cat("Resolved veg_path :", veg_path,  "exists:", file.exists(veg_path),  "\n")
cat("Resolved haz_path :", haz_path,  "exists:", file.exists(haz_path),  "\n")
cat("Resolved gdp_path :", gdp_path,  "exists:", file.exists(gdp_path),  "\n")

if (is.na(temp_path) || !file.exists(temp_path)) stop("Temperature raster not found or unreadable; ensure TEMP.tif exists and the path is accessible.")
if (is.na(pop_path)  || !file.exists(pop_path))  stop("Population raster not found or unreadable; ensure GHS_POP...tif exists and the path is accessible.")
```

```{r env-extract-1}
env_static <- world %>%
  transmute(country_iso) %>%
  left_join(
    extract_stat(world, temp_path, fun = "mean", fact = 40) %>%
      rename(temp_celsius = value),
    by = "country_iso"
  ) %>%
  left_join(
    extract_stat(world, pop_path, fun = "sum", fact = 60) %>%  # POP is huge
      rename(population = value),
    by = "country_iso"
  ) %>%
  left_join({
    if (file.exists(veg_path)) {
      r <- rast(veg_path)
      # Align CRS to raster if needed
      world_aligned <- if (!is.na(crs(r)) && crs(r) != st_crs(world)) st_transform(world, crs(r)) else world
      world_aligned$id <- seq_len(nrow(world_aligned))

      # Downsample land cover before classifying to save RAM
      r <- aggregate(r, fact = 40, fun = median, na.rm = TRUE)

      # Classify to a vegetation indicator and average per country
      r_veg <- classify(
        r,
        rbind(
          c(-Inf, 10, 0),
          c(10, 200, 1),
          c(200, Inf, 0)
        )
      )
      z <- terra::zonal(r_veg, vect(world_aligned), fun = "mean", na.rm = TRUE)
      frac <- rep(NA_real_, nrow(world_aligned))
      frac[match(z$zone, world_aligned$id)] <- z$mean
      tibble(country_iso = world_aligned$country_iso, vegetation_fraction = frac)
    } else {
      warning("Missing land cover raster: ", veg_path)
      tibble(country_iso = world$country_iso, vegetation_fraction = NA_real_)
    }
  }, by = "country_iso") %>%
  left_join(
    extract_stat(world, haz_path, fun = "mean", fact = 40) %>%
      rename(hazard_score = value),
    by = "country_iso"
  ) %>%
  mutate(
    pm25_mean = NA_real_,
    precip_mm_month = NA_real_
  )

```

```{r env-extract-2}
# GDP panel (1990-2015 bands)
gdp_panel <- {
  if (file.exists(gdp_path)) {
    r <- rast(gdp_path)
    # Infer years from layer order
    years <- 1990 + (seq_len(nlyr(r)) - 1)
    map_dfr(seq_along(years), function(i) {
      vals <- extract_stat(world, gdp_path, fun = sum, band = i) %>% rename(gdp_ppp = value)
      vals$year <- years[i]
      vals
    })
  } else {
    warning("Missing GDP NetCDF: ", gdp_path)
    tibble(country_iso = character(), year = integer(), gdp_ppp = numeric())
  }
}
```

```{r}
print(temp_path)
file.exists(temp_path)

```

## Build Panel Dataset

```{r build}
lgii_years <- sort(unique(lgii$year))

env_panel <- expand_grid(country_iso = env_static$country_iso, year = lgii_years) %>%
  left_join(env_static, by = "country_iso") %>%
  left_join(gdp_panel, by = c("country_iso", "year"))

data_merged <- lgii %>%
  inner_join(env_panel, by = c("country_iso", "year"))

data_enriched <- data_merged %>%
  mutate(
    ndvi_mean = vegetation_fraction,
    z_pm25   = if_else(is.na(pm25_mean), 0, zscore(pm25_mean)),
    z_hazard = if_else(is.na(hazard_score), 0, zscore(hazard_score)),
    z_temp   = if_else(is.na(temp_celsius), 0, zscore(temp_celsius)),
    z_ndvi   = if_else(is.na(ndvi_mean), 0, zscore(ndvi_mean)),
    z_precip = if_else(is.na(precip_mm_month), 0, zscore(precip_mm_month)),
    environmental_stress_index = z_pm25 + z_hazard + z_temp + z_precip - z_ndvi,

    population_millions = population / 1e6,
    gdp = gdp_ppp,

    socioeconomic_vulnerability =
      coalesce(zscore(pdens), 0) +
      0.6 * coalesce(zscore(population_millions), 0) +
      (-0.8) * coalesce(zscore(kaopen), 0) +
      (-0.5) * coalesce(zscore(gdp), 0),

    csvi = 0.6 * minmax(environmental_stress_index) +
           0.4 * minmax(socioeconomic_vulnerability)
  ) %>%
  group_by(country_iso) %>%
  arrange(year, .by_group = TRUE) %>%
  mutate(delta_gini = gini - lag(gini)) %>%
  ungroup()


glimpse(data_enriched)
```

## Modeling

```{r modeling}
df_model <- data_enriched %>%
  drop_na(gini)

features <- c("pm25_mean","ndvi_mean","vegetation_fraction","temp_celsius",
              "precip_mm_month","hazard_score","population_millions",
              "density_per_km2","economic_openness","gdp_ppp",
              "environmental_stress_index","socioeconomic_vulnerability")

safe_impute <- function(v) {
  med <- suppressWarnings(median(v, na.rm = TRUE))
  if (is.na(med)) med <- 0
  if_else(is.na(v), med, v)
}

if (nrow(df_model) >= 2) {
  X <- df_model %>%
    select(any_of(features)) %>%
    mutate(across(everything(), safe_impute))
  y <- df_model$gini

  # Train/test split
  set.seed(42)
  idx <- sample(seq_len(nrow(X)), size = max(1, ceiling(0.75 * nrow(X))))
  X_train <- X[idx, ]; X_test <- X[-idx, ]
  y_train <- y[idx];  y_test <- y[-idx]

  lin <- lm(y_train ~ ., data = X_train)
  lin_pred <- predict(lin, X_test)

  rf <- randomForest(x = X_train, y = y_train, ntree = 300, mtry = floor(sqrt(ncol(X_train))), nodesize = 2)
  rf_pred <- predict(rf, X_test)

  metrics <- function(truth, pred) {
    tibble(
      r2 = cor(truth, pred)^2,
      mae = mean(abs(truth - pred)),
      rmse = sqrt(mean((truth - pred)^2))
    )
  }

  lin_metrics <- metrics(y_test, lin_pred)
  rf_metrics <- metrics(y_test, rf_pred)

  lin_metrics
  rf_metrics

  feature_importance <- tibble(
    feature = colnames(rf$importance),
    importance = as.numeric(rf$importance)
  ) %>% arrange(desc(importance))

  head(feature_importance)
} else {
  message("Insufficient non-NA rows to fit models.")
  lin_metrics <- rf_metrics <- tibble(r2 = NA_real_, mae = NA_real_, rmse = NA_real_)
  feature_importance <- tibble(feature = character(), importance = numeric())
}
```

### Delta-Gini Models

```{r delta}
df_delta <- data_enriched %>% drop_na(delta_gini)
delta_results <- if (nrow(df_delta) > 2) {
  Xd <- df_delta %>%
    select(any_of(features)) %>%
    mutate(across(everything(), safe_impute))
  yd <- df_delta$delta_gini
  set.seed(42)
  idxd <- sample(seq_len(nrow(Xd)), size = ceiling(0.75 * nrow(Xd)))
  lin_d <- lm(yd[idxd] ~ ., data = Xd[idxd, ])
  rf_d <- randomForest(x = Xd[idxd, ], y = yd[idxd], ntree = 200, nodesize = 2)
  tibble(
    model = c("delta_linear", "delta_random_forest"),
    r2 = c(metrics(yd[-idxd], predict(lin_d, Xd[-idxd, ]))$r2,
           metrics(yd[-idxd], predict(rf_d, Xd[-idxd, ]))$r2),
    mae = c(metrics(yd[-idxd], predict(lin_d, Xd[-idxd, ]))$mae,
            metrics(yd[-idxd], predict(rf_d, Xd[-idxd, ]))$mae),
    rmse = c(metrics(yd[-idxd], predict(lin_d, Xd[-idxd, ]))$rmse,
             metrics(yd[-idxd], predict(rf_d, Xd[-idxd, ]))$rmse)
  )
} else {
  tibble()
}

delta_results

metrics_tbl <- bind_rows(
  lin_metrics %>% mutate(model = "linear_regression"),
  rf_metrics %>% mutate(model = "random_forest"),
  delta_results
) %>% select(model, r2, mae, rmse)
```

## Clustering Profiles

```{r clustering}
latest <- data_enriched %>%
  group_by(country_iso) %>%
  slice_tail(n = 1) %>%
  ungroup()

feat_cols <- intersect(c(features, "csvi"), colnames(latest))
if (length(feat_cols) > 0 && nrow(latest) >= 2) {
  mat <- latest %>%
    select(all_of(feat_cols)) %>%
    mutate(across(everything(), safe_impute)) %>%
    as.matrix()
  k <- min(4, nrow(mat))
  if (k < 2) {
    "Not enough rows to cluster."
  } else {
    km <- tryCatch(kmeans(mat, centers = k, nstart = 25), error = function(e) NULL)
    if (is.null(km)) {
      "Clustering failed (insufficient variation/rows)."
    } else {
      latest$cluster <- factor(km$cluster)
      latest %>% select(country_iso, cluster)
    }
  }
} else {
  "Insufficient features/rows to cluster."
}
```
## Spatial autocorrelation (Moran's I)
```{r moran}
compute_moran_csvi <- function(df, shapes) {
  latest_csvi <- df %>%
    drop_na(csvi) %>%
    group_by(country_iso) %>%
    slice_tail(n = 1) %>%
    ungroup()
  merged <- shapes %>%
    select(country_iso, geometry) %>%
    inner_join(latest_csvi, by = "country_iso") %>%
    drop_na(csvi)
  if (nrow(merged) < 3) return(tibble())
  cent <- st_centroid(st_geometry(merged))
  coords <- st_coordinates(cent)
  x <- merged$csvi
  dist_mat <- as.matrix(dist(coords))
  diag(dist_mat) <- NA
  w <- 1 / (dist_mat + 1e-6)
  w[!is.finite(w)] <- 0
  s0 <- sum(w, na.rm = TRUE)
  if (s0 == 0) return(tibble())
  x_dev <- x - mean(x, na.rm = TRUE)
  num <- sum(w * (outer(x_dev, x_dev)), na.rm = TRUE)
  den <- sum(x_dev^2, na.rm = TRUE)
  if (den == 0) return(tibble())
  moran_i <- length(x_dev) / s0 * (num / den)
  tibble(moran_i_csvi = moran_i, n_countries = length(x_dev))
}

spatial_stats <- compute_moran_csvi(data_enriched, world)
spatial_stats
```
```

## Visualizations

```{r figures, fig.width=7, fig.height=5}
# Scatter: stress vs. gini
ggplot(data_enriched, aes(environmental_stress_index, gini)) +
  geom_point(alpha = 0.7) +
  geom_smooth(method = "lm", se = FALSE, color = "steelblue") +
  labs(title = "Environmental Stress vs. Gini", x = "Environmental Stress Index", y = "Gini")
```

```{r timeseries, fig.width=9, fig.height=5}
ggplot(data_enriched, aes(year, gini, color = country_iso)) +
  geom_line() +
  geom_point() +
  labs(title = "Gini over Time", x = "Year", y = "Gini")
```

```{r choropleth, message=FALSE, warning=FALSE, fig.width=10, fig.height=6}
latest_map <- latest %>% select(country_iso, csvi)
world_csvi <- world %>% left_join(latest_map, by = "country_iso") %>% drop_na(csvi)

if (nrow(world_csvi) > 0) {
  ggplot(world_csvi) +
    geom_sf(aes(fill = csvi), color = "gray30", size = 0.1) +
    scale_fill_viridis_c(option = "C") +
    labs(title = "Climate-Socioeconomic Vulnerability Index (latest year)", fill = "CSVI") +
    theme(axis.text = element_blank(), axis.ticks = element_blank())
}
```

## Save Outputs

```{r save}
dir.create("reports", showWarnings = FALSE, recursive = TRUE)
write_csv(data_enriched, "reports/merged_dataset.csv")
write_csv(feature_importance, "reports/feature_importance.csv")
write_csv(metrics_tbl, "reports/metrics.csv")
write_json(metrics_tbl, "reports/metrics.json", pretty = TRUE, auto_unbox = TRUE)
if (nrow(spatial_stats) > 0) {
  write_json(spatial_stats, "reports/spatial.json", pretty = TRUE, auto_unbox = TRUE)
}
ggsave("reports/stress_vs_gini.png", width = 7, height = 5)
ggsave("reports/gini_timeseries.png", width = 9, height = 5)
```

Knit this file to produce the merged dataset, model metrics, and figures analogous to the Python pipeline.
